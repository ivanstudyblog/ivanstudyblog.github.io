---
layout: post
title: (Day 365) Learning about feature stores
categories: [theory,mlops]
---
`
# Hello :) Today is Day 365!
A quick summary of today:
* watching feature store videos by Hopsworks academy
* using the Hopsworks python API and the UI

---

## [Learning about Feature Stores w/ Hopsworks Academy](https://www.youtube.com/playlist?list=PLgN6fhzkSui_YzFsY6E1f_U86OATEYLC6)

### Batch & Real-Time Machine Learning Systems; A better framework with Hopsworks Feature Store

<img width="642" alt="image" src="https://github.com/user-attachments/assets/f040d770-841f-4a3d-a76a-ceb702d4b993" />

They mention that an ML model trained on static data doesn't qualify as an ML system - it's a one-off ML experiment and we can generate one-off preds with that model on that static data. For an *ML system* we need to have new data coming in and the model will generate more value when it keeps making predictions on more and more data. 

This is their model for building ML systems - they call it 'The Feature, Training, and Inference pipeline' model.

<img width="649" alt="image" src="https://github.com/user-attachments/assets/a5e3fade-ca6a-4cd0-b67b-b7819b17e56d" />

An ML pipeline consists of these 3 pipelines.

The 3 pipes can be developed separately and is good for system modularity so that even different roles/teams develop/maintain each pipeline (if needed).

<img width="425" alt="image" src="https://github.com/user-attachments/assets/29768efe-ada3-41a2-a72a-b22cccc00c71" />

Pipelines also need to be orchestrated, and given the modularity we can run them on different platforms depending on what we have/use case

<img width="424" alt="image" src="https://github.com/user-attachments/assets/77ac73dd-603b-40ce-b3bb-c4ca160c75c0" />

We also need to make sure we test our pipelines. We need to test each part of our pipelines:

<img width="318" alt="image" src="https://github.com/user-attachments/assets/1167ab61-17f3-46aa-a25b-5acc692509e0" />

And then we can do A/B testing, etc. 

When we have a new model, we might have a new set of features that were used to train that model so we need to connect model versions to feature versions. And Hopsworks helps with this.

<img width="329" alt="image" src="https://github.com/user-attachments/assets/ab10bc8c-8d9b-485c-896c-c887cd35d60d" />

Hopsworks stitches all these pipes together, and each of their outputs can be stored in Hopsworks as well

<img width="430" alt="image" src="https://github.com/user-attachments/assets/8e0eea7d-e9e8-45d5-be51-b148ed406569" />

### Feature Pipelines in Production with Hopsworks: Code, Deployment & Monitoring

Pipelines in prod:

* managing the codebase - like github
* deployment

We can schedule and run jobs from the Hopsworks UI:

<img width="1511" alt="image" src="https://github.com/user-attachments/assets/66ca368c-ee54-46d9-8c95-971fce4b9208" />

We can also see more detailed info about each run:

<img width="750" alt="image" src="https://github.com/user-attachments/assets/0dcac79d-5c85-4575-8b0e-fee2de84c04f" />

* monitoring - we can set alerts

### What is a feature store for ML ?

<img width="1300" alt="image" src="https://github.com/user-attachments/assets/bf8e51dd-93ef-4e9d-812d-b1e502ca07ed" />

They help:

* maintain models
* train models
* improve model

Features are the data for AI, and as such can be regarded as the fuel for AI. 

<img width="705" alt="image" src="https://github.com/user-attachments/assets/83b48935-9ea5-4cf5-ba2d-7f55b7caec91" />

Features are used throughout all the stages of an ML lifecycle and managing them can be a challenge as they need to be properly organised, stored and readily available for models. This is where the feature store comes in. It manages, stores, and provides access to both historical and real-time features. 

Who does it help?

Mostly DEs, DSs, MLEs

<img width="632" alt="image" src="https://github.com/user-attachments/assets/be2277e0-7c1b-4989-94cb-a4a0130a1423" />

The feature store helps make more models and productionise them, faster. It's value comes in its ability to bridge the gap between different stages of the model lifecycle and the many stakeholders involved. 

### Deploying Managed Hopswork Via the UI or Terraform

This video was just showing how to set up Hopsworks either through the UI - connecting with AWS/GCP/Azure, or using Hopswork's pre-set Terraform platform. 

### Real-Time Inference: How to retrieve data from Hopsworks

The Hopsworks API provides us with very low-latency options for retrieving features for real-time inference cases like fraud detection. 

Features can be viewed in the Feature View:

<img width="794" alt="image" src="https://github.com/user-attachments/assets/3f37bb96-e1c8-49eb-9a1f-25bff8f56e3e" />

Once we click on fraud, we can see:

<img width="866" alt="image" src="https://github.com/user-attachments/assets/67ed22cb-fc4e-4b4e-b883-3bb1635e4dbf" />

More detailed info. We can even see the `label_encoder` tag which means that that column has had a transformation applied to it (i.e. scikit-leanr's le)

And we can interact with this using Hopsworks' Python API.

I will just give a list of the Hopsworks feature discussed as I will do a hopsworks tutorial I found after this ~

* we can create train/test splits alongside extra info like stats and see them through the UI
* creating a [feature view](https://www.hopsworks.ai/dictionary/feature-view): a curated selection of features (and optionally labels) from one or more feature groups within a feature store and serves as a logical representation tailored for specific machine learning models

We can also see lineage:

<img width="819" alt="image" src="https://github.com/user-attachments/assets/aa5680cd-fa7c-4fca-9c04-b3fad742a1b4" />

* [external feature groups](https://docs.hopsworks.ai/3.2/concepts/fs/feature_group/external_fg/): allow users to register features stored in external systems (like Snowflake, BigQuery, S3) within Hopsworks, providing a unified platform for data scientists to access all features
* streaming feature pipelines: we can use different streaming platforms (i.e. Spark Streaming, Beam, Flink)
* [feature groups](https://www.hopsworks.ai/dictionary/feature-groups): a structured table of features with an online store for fast, real-time access to the latest feature values and an offline store for historical data used in training and batch inference
* [versioning](https://docs.hopsworks.ai/feature-store-api/2.5.9/generated/versioning/): there is schema (metadata for feature views, feature groups - the features included, tags, other metadata) and data versioning (actual data versioning)

---

## Hopsworks Tutorial - Part 01: Feature Pipeline

I created a profile on hopsworks.ai and there was a tutorial button with:

<img width="1511" alt="image" src="https://github.com/user-attachments/assets/597a31b2-2958-4503-a527-ecafaf4c1541" />

So I cliced on the 1st one and it took me to [this colab notebook](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/churn/1_churn_feature_pipeline.ipynb).

Loaded some data, and logged in Hopsworks with an API key ~ 

<img width="692" alt="image" src="https://github.com/user-attachments/assets/05b61e17-e4a8-49ab-93ad-36bd846db01e" />

* create a feature group

```python
customer_info_fg = fs.get_or_create_feature_group(
    name="customer_info",
    version=1,
    description="Customer info for churn prediction.",
    primary_key=['customerID'],
    event_time="datetime",
)
```

* insert data into the feature group

```python
customer_info_fg.insert(customer_info_df)
```

I inserted data for all 3 datasets:

<img width="1511" alt="image" src="https://github.com/user-attachments/assets/41160b30-b4d7-4695-a221-87f4659d81ad" />

Next is Part 2

---

## [Hopsworks Feature Store - Part 02: Training Pipeline](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/churn/2_churn_training_pipeline.ipynb)

![image](https://github.com/user-attachments/assets/9b42a0f4-d2c7-4cf0-a041-629e7ce049c0)

**Load and select features from feature groups**

```python
# Retrieve feature groups
customer_info_fg = fs.get_feature_group(
    name="customer_info",
    version=1,
)

demography_fg = fs.get_feature_group(
    name="customer_demography_info",
    version=1,
)

subscriptions_fg = fs.get_feature_group(
    name="customer_subscription_info",
    version=1,
)

selected_features = customer_info_fg.select_except(["customerid", "datetime"]) \
    .join(demography_fg.select_except(["customerid"])) \
    .join(subscriptions_fg.select_except(["datetime"]))
```

**Transformation**

```python
# Load transformation functions from the feature store
min_max_scaler = fs.get_transformation_function(name="min_max_scaler")
label_encoder = fs.get_transformation_function(name="label_encoder")

# Define lists of numerical and categorical features
numerical_features = ["tenure", "monthlycharges", "totalcharges"]
categorical_features = [
    "multiplelines", "internetservice", "onlinesecurity", "onlinebackup",
    "deviceprotection", "techsupport", "streamingmovies", "streamingtv",
    "phoneservice", "paperlessbilling", "contract", "paymentmethod", "gender", 
    "dependents", "partner",
]

# Map features to their corresponding transformation functions
transformation_functions = []

# For numerical features, use the min_max_scaler transformation
for feature in numerical_features:
    transformation_functions.append(min_max_scaler(feature))

# For categorical features, use the label_encoder transformation
for feature in categorical_features:
    transformation_functions.append(label_encoder(feature))
```

**Create a feature view**

_The Feature Views allows schema in form of a query with filters, define a model target feature/label and additional transformation functions._

```python
feature_view = fs.get_or_create_feature_view(
        name = 'churn_feature_view',
        version = 1,
        labels=["churn"],
        transformation_functions=transformation_functions,
        query=selected_features,
)
```

I can see it in the UI

<img width="672" alt="image" src="https://github.com/user-attachments/assets/9feb50c4-6860-420f-9fc2-b5eba0b8dc98" />

<img width="1067" alt="image" src="https://github.com/user-attachments/assets/6d814467-99ba-4dc8-97ee-a2ccda92f33a" />


**Split data, train a model, check evam metrics**

Then we can get the Hopsworks model registry:

```python
mr = project.get_model_registry()
```

**Model schema**

The model needs to be set up with a Model Schema, which describes the inputs and outputs for a model.

A Model Schema can be automatically generated from training examples, as shown below.

```python
from hsml.schema import Schema
from hsml.model_schema import ModelSchema

# Create input schema using X_train
input_schema = Schema(X_train)

# Create output schema using y_train
output_schema = Schema(y_train)

# Create a ModelSchema object specifying the input and output schemas
model_schema = ModelSchema(
    input_schema=input_schema, 
    output_schema=output_schema,
)

# Convert the model schema to a dictionary
model_schema.to_dict()
```

Here is the dict model schema:

```
{'input_schema': {'columnar_schema': [{'name': 'seniorcitizen',
    'type': 'int64'},
   {'name': 'label_encoder_contract_', 'type': 'int64'},
   {'name': 'label_encoder_dependents_', 'type': 'int64'},
   {'name': 'label_encoder_deviceprotection_', 'type': 'int64'},
   {'name': 'label_encoder_gender_', 'type': 'int64'},
   {'name': 'label_encoder_internetservice_', 'type': 'int64'},
   {'name': 'label_encoder_multiplelines_', 'type': 'int64'},
   {'name': 'label_encoder_onlinebackup_', 'type': 'int64'},
   {'name': 'label_encoder_onlinesecurity_', 'type': 'int64'},
   {'name': 'label_encoder_paperlessbilling_', 'type': 'int64'},
   {'name': 'label_encoder_partner_', 'type': 'int64'},
   {'name': 'label_encoder_paymentmethod_', 'type': 'int64'},
   {'name': 'label_encoder_phoneservice_', 'type': 'int64'},
   {'name': 'label_encoder_streamingmovies_', 'type': 'int64'},
   {'name': 'label_encoder_streamingtv_', 'type': 'int64'},
   {'name': 'label_encoder_techsupport_', 'type': 'int64'},
   {'name': 'min_max_scaler_monthlycharges_', 'type': 'float64'},
   {'name': 'min_max_scaler_tenure_', 'type': 'float64'},
   {'name': 'min_max_scaler_totalcharges_', 'type': 'float64'}]},
 'output_schema': {'columnar_schema': [{'name': 'churn', 'type': 'int64'}]}}
```

Then we can save articacts and the model:

```python
model_dir = "churn_model"

if not os.path.isdir(model_dir):
    os.mkdir(model_dir)

model.save_model(model_dir + "/model.json")
figure_cm.figure.savefig(model_dir + '/confusion_matrix.png')

# Create a model in the model registry
model = mr.python.create_model(
    name="churnmodel",
    description="Churn Model",
    input_example=X_train.sample(),
    model_schema=model_schema,
)

model.save(model_dir)
```

And I can see it in the UI:

<img width="792" alt="image" src="https://github.com/user-attachments/assets/17f051e2-74d4-477e-bfbc-be1a5c5dc4e3" />

And inside I can see all other info:

<img width="616" alt="image" src="https://github.com/user-attachments/assets/1f391859-a044-4f7c-b721-b7cd05b7a883" />

Next is Part 3

---

## [Fetch and test the model](https://colab.research.google.com/github/logicalclocks/hopsworks-tutorials/blob/master/churn/3_churn_batch_inference.ipynb#scrollTo=38d83203)

```python
# Retrieve the model from the model registry
retrieved_model = mr.get_model(
    name="churnmodel",
    version=1,
)

# Download the saved model files to a local directory
saved_model_dir = retrieved_model.download()
# Initialize the model
model = XGBClassifier()

# Load the model from a saved JSON file
model.load_model(saved_model_dir + "/model.json")
```

And then we can use it as usual for predictions. 

We can get batch data from our feature view:

```python
# Initialize batch scoring
feature_view.init_batch_scoring(1)

# Get the batch data
batch_data = feature_view.get_batch_data()

# Display the first three rows of the batch_data
batch_data.head(3)
```

We can also load any transformers needed for features (i.e. min-max scaler)

```python
df_all = batch_data.copy()
fv_transformation_functions = feature_view._batch_scoring_server.model_dependent_transformation_functions

for transformation_function in fv_transformation_functions:
    udf = transformation_function.hopsworks_udf
    if udf.function_name == "min_max_scaler":
        transformed_features = udf.transformation_features[0]
        transformed_feature_name = udf.output_column_names[0]
        stats = udf.transformation_statistics
        df_all[transformed_features] = df_all[transformed_feature_name].map(lambda x: x*(stats.feature.max-stats.feature.min)+stats.feature.min)
        
    
    if udf.function_name == "label_encoder":
        transformed_features = udf.transformation_features[0]
        transformed_feature_name = udf.output_column_names[0]
        stats = udf.transformation_statistics
        unique_data = sorted([value for value in stats.feature.unique_values])
        index_to_value = {index: value for index, value in enumerate(unique_data)}
        df_all[transformed_features] = df_all[transformed_feature_name].map(lambda x: index_to_value[x])
```

This comes at the end of the notebook, but we can also enable extra stats, correlations and graphs for feature groups:

```python
customer_info_fg = fs.get_feature_group("customer_info", version = 1)
customer_info_fg.statistics_config = {
    "enabled": True,
    "histograms": True,
    "correlations": True,
}

customer_info_fg.update_statistics_config()
customer_info_fg.compute_statistics()
```

In the UI we can see:

<img width="1451" alt="image" src="https://github.com/user-attachments/assets/e63d6944-a2e3-4214-a43d-bcad731404c6" />

<img width="1459" alt="image" src="https://github.com/user-attachments/assets/d6e762e3-fcbf-4681-94f9-f7fbbd52bb0a" />

<img width="1435" alt="image" src="https://github.com/user-attachments/assets/aef406b5-d050-423c-a8f7-519e93b01e7d" />

On the [Hopsworks repo](https://github.com/logicalclocks/hopsworks-tutorials) they have a few more notebook tutorials which is great. 

I saw that Zach Wilson posted two new lectures + labs but I forgot my tablet so I will cover them by myself tomorrow as well.

I will do them on my own as I think this is the last study material I will post on the blog ðŸ˜¢ 

---

Today's post is a bit shorter and earlier as I am going out to meet the New Year :) 

Tomorrow I will post about my journey, what I learned, thoughts, list of books & courses, summary ~

Happy New Year ðŸ¥³

That is all for today!

And for the last time ~ See you tomorrow :)
